"""
AI Town é…ç½®åŠ è½½å™¨
è‡ªåŠ¨ä» .env æ–‡ä»¶åŠ è½½é…ç½®ï¼Œæ”¯æŒè¿è¡Œæ—¶é…ç½®ä¿®æ”¹
"""

import os
from pathlib import Path
from typing import Dict, Any

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent

def load_env_file(env_path: Path = None) -> Dict[str, str]:
    """åŠ è½½ .env æ–‡ä»¶"""
    if env_path is None:
        env_path = PROJECT_ROOT / ".env"
    
    config = {}
    
    if not env_path.exists():
        print(f"è­¦å‘Š: é…ç½®æ–‡ä»¶ {env_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return config
    
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                
                # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                if not line or line.startswith('#'):
                    continue
                
                # è§£æ KEY=VALUE
                if '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip()
                    
                    # ç§»é™¤å¼•å·
                    if value.startswith('"') and value.endswith('"'):
                        value = value[1:-1]
                    elif value.startswith("'") and value.endswith("'"):
                        value = value[1:-1]
                    
                    config[key] = value
                    
                    # åŒæ—¶è®¾ç½®åˆ°ç¯å¢ƒå˜é‡ä¸­
                    os.environ[key] = value
                    
        print(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {env_path}")
        print(f"ğŸ“‹ åŠ è½½äº† {len(config)} é¡¹é…ç½®")
        
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    return config

def get_llm_config_for_agent(agent_name: str) -> Dict[str, Any]:
    """è·å–æŒ‡å®šæ™ºèƒ½ä½“çš„ LLM é…ç½®"""
    try:
        from ai_town.config import LLM_CONFIG, AGENT_LLM_CONFIG
    except ImportError:
        import sys
        sys.path.append(str(PROJECT_ROOT))
        from ai_town.config import LLM_CONFIG, AGENT_LLM_CONFIG
    
    # è·å–æ™ºèƒ½ä½“ç‰¹å®šé…ç½®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    agent_config = AGENT_LLM_CONFIG.get(agent_name, AGENT_LLM_CONFIG["default"])
    
    return {
        "provider": agent_config["provider"],
        "use_llm_for_planning": agent_config["use_llm_for_planning"],
        "use_llm_for_conversation": agent_config["use_llm_for_conversation"],
        "use_llm_for_reflection": agent_config["use_llm_for_reflection"],
        "provider_config": LLM_CONFIG.get(agent_config["provider"], {})
    }

def get_current_llm_model() -> str:
    """è·å–å½“å‰é…ç½®çš„ LLM æ¨¡å‹"""
    return os.environ.get('OLLAMA_MODEL', 'deepseek-r1:1.5b')

def switch_llm_model(model_name: str):
    """å¿«é€Ÿåˆ‡æ¢ LLM æ¨¡å‹"""
    os.environ['OLLAMA_MODEL'] = model_name
    print(f"âœ… LLM æ¨¡å‹å·²åˆ‡æ¢ä¸º: {model_name}")

def show_current_config():
    """æ˜¾ç¤ºå½“å‰ LLM é…ç½®"""
    try:
        from ai_town.config import LLM_CONFIG, AGENT_LLM_CONFIG
    except ImportError:
        import sys
        sys.path.append(str(PROJECT_ROOT))
        from ai_town.config import LLM_CONFIG, AGENT_LLM_CONFIG
    
    print("ğŸ”§ å½“å‰ AI Town LLM é…ç½®:")
    print("=" * 50)
    
    print(f"é»˜è®¤æä¾›å•†: {LLM_CONFIG['default_provider']}")
    print(f"Ollama æ¨¡å‹: {get_current_llm_model()}")
    print(f"æ•…éšœè½¬ç§»é“¾: {' -> '.join(LLM_CONFIG['fallback_chain'])}")
    
    print("\nğŸ“‹ æ™ºèƒ½ä½“é…ç½®:")
    for agent_name, config in AGENT_LLM_CONFIG.items():
        if agent_name != "default":
            print(f"  {agent_name}: {config['provider']}")

# è‡ªåŠ¨åŠ è½½é…ç½®
def initialize_config():
    """åˆå§‹åŒ–é…ç½®ç³»ç»Ÿ"""
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– AI Town é…ç½®...")
    load_env_file()
    show_current_config()

if __name__ == "__main__":
    initialize_config()
